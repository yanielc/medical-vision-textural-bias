Wed Mar 31 12:17:23 2021       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla T4            On   | 00000000:00:0F.0 Off |                    0 |
| N/A   44C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   1  Tesla T4            On   | 00000000:00:10.0 Off |                    0 |
| N/A   38C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
MONAI version: 0.5.dev2113
Numpy version: 1.19.2
Pytorch version: 1.8.0
MONAI flags: HAS_EXT = False, USE_COMPILED = False
MONAI rev id: b3cc668c924b2a7e6b822416f4d920a098c27704

Optional dependencies:
Pytorch Ignite version: 0.4.4
Nibabel version: 3.2.1
scikit-image version: 0.17.2
Pillow version: 8.1.2
Tensorboard version: 1.15.0
gdown version: 3.12.2
TorchVision version: 0.9.0
ITK version: NOT INSTALLED or UNKNOWN VERSION.
tqdm version: 4.50.2
lmdb version: NOT INSTALLED or UNKNOWN VERSION.
psutil version: NOT INSTALLED or UNKNOWN VERSION.

For details about installing the optional dependencies, please visit:
    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies

Loading dataset:   0%|          | 0/50 [00:00<?, ?it/s]Loading dataset:   2%|▏         | 1/50 [00:03<03:14,  3.97s/it]Loading dataset:  10%|█         | 5/50 [00:07<02:17,  3.06s/it]Loading dataset:  18%|█▊        | 9/50 [00:11<01:38,  2.41s/it]Loading dataset:  20%|██        | 10/50 [00:11<01:10,  1.77s/it]Loading dataset:  26%|██▌       | 13/50 [00:14<00:58,  1.58s/it]Loading dataset:  34%|███▍      | 17/50 [00:18<00:44,  1.36s/it]Loading dataset:  36%|███▌      | 18/50 [00:18<00:31,  1.00it/s]Loading dataset:  38%|███▊      | 19/50 [00:18<00:22,  1.36it/s]Loading dataset:  42%|████▏     | 21/50 [00:21<00:28,  1.02it/s]Loading dataset:  44%|████▍     | 22/50 [00:21<00:20,  1.34it/s]Loading dataset:  46%|████▌     | 23/50 [00:22<00:18,  1.48it/s]Loading dataset:  50%|█████     | 25/50 [00:25<00:23,  1.05it/s]Loading dataset:  54%|█████▍    | 27/50 [00:25<00:16,  1.40it/s]Loading dataset:  58%|█████▊    | 29/50 [00:29<00:21,  1.00s/it]Loading dataset:  66%|██████▌   | 33/50 [00:32<00:16,  1.02it/s]Loading dataset:  70%|███████   | 35/50 [00:33<00:10,  1.41it/s]Loading dataset:  74%|███████▍  | 37/50 [00:36<00:13,  1.03s/it]Loading dataset:  82%|████████▏ | 41/50 [00:40<00:08,  1.01it/s]Loading dataset:  90%|█████████ | 45/50 [00:43<00:04,  1.04it/s]Loading dataset:  92%|█████████▏| 46/50 [00:43<00:02,  1.39it/s]Loading dataset:  98%|█████████▊| 49/50 [00:46<00:00,  1.35it/s]Loading dataset: 100%|██████████| 50/50 [00:46<00:00,  1.83it/s]Loading dataset: 100%|██████████| 50/50 [00:46<00:00,  1.08it/s]
Loading dataset:   0%|          | 0/50 [00:00<?, ?it/s]Loading dataset:   2%|▏         | 1/50 [00:03<02:55,  3.57s/it]Loading dataset:   4%|▍         | 2/50 [00:04<02:08,  2.67s/it]Loading dataset:  10%|█         | 5/50 [00:07<01:38,  2.19s/it]Loading dataset:  14%|█▍        | 7/50 [00:07<01:08,  1.58s/it]Loading dataset:  18%|█▊        | 9/50 [00:10<01:05,  1.61s/it]Loading dataset:  20%|██        | 10/50 [00:11<00:46,  1.17s/it]Loading dataset:  22%|██▏       | 11/50 [00:11<00:35,  1.09it/s]Loading dataset:  26%|██▌       | 13/50 [00:14<00:42,  1.15s/it]Loading dataset:  34%|███▍      | 17/50 [00:18<00:35,  1.07s/it]Loading dataset:  42%|████▏     | 21/50 [00:22<00:29,  1.02s/it]Loading dataset:  46%|████▌     | 23/50 [00:22<00:20,  1.32it/s]Loading dataset:  50%|█████     | 25/50 [00:25<00:26,  1.05s/it]Loading dataset:  54%|█████▍    | 27/50 [00:26<00:18,  1.27it/s]Loading dataset:  58%|█████▊    | 29/50 [00:29<00:21,  1.02s/it]Loading dataset:  60%|██████    | 30/50 [00:29<00:16,  1.23it/s]Loading dataset:  64%|██████▍   | 32/50 [00:29<00:10,  1.67it/s]Loading dataset:  66%|██████▌   | 33/50 [00:32<00:23,  1.37s/it]Loading dataset:  72%|███████▏  | 36/50 [00:33<00:14,  1.00s/it]Loading dataset:  74%|███████▍  | 37/50 [00:36<00:22,  1.72s/it]Loading dataset:  82%|████████▏ | 41/50 [00:40<00:13,  1.46s/it]Loading dataset:  86%|████████▌ | 43/50 [00:40<00:07,  1.10s/it]Loading dataset:  90%|█████████ | 45/50 [00:44<00:06,  1.27s/it]Loading dataset:  94%|█████████▍| 47/50 [00:44<00:02,  1.07it/s]Loading dataset:  98%|█████████▊| 49/50 [00:46<00:00,  1.01it/s]Loading dataset: 100%|██████████| 50/50 [00:46<00:00,  1.38it/s]Loading dataset: 100%|██████████| 50/50 [00:46<00:00,  1.07it/s]root_dir /vol/bitbucket/yc7620/90_data/52_MONAI_DATA_DIRECTORY/


training transforms:  (<monai.transforms.io.dictionary.LoadImaged object at 0x7fdfa37d0d90>, <monai.transforms.utility.dictionary.AsChannelFirstd object at 0x7fdfa376c100>, <__main__.ConvertToMultiChannelBasedOnBratsClassesd object at 0x7fdfa376c1c0>, <monai.transforms.spatial.dictionary.Spacingd object at 0x7fdfa376c220>, <monai.transforms.spatial.dictionary.Orientationd object at 0x7fe03a0e2370>, <monai.transforms.croppad.dictionary.RandSpatialCropd object at 0x7fdfa37d0070>, <monai.transforms.spatial.dictionary.RandFlipd object at 0x7fdfa37bd8e0>, <monai.transforms.intensity.dictionary.NormalizeIntensityd object at 0x7fdfa37bdfd0>, <monai.transforms.intensity.dictionary.RandScaleIntensityd object at 0x7fdfa37bde50>, <monai.transforms.intensity.dictionary.RandShiftIntensityd object at 0x7fdfa37bdd90>, <monai.transforms.utility.dictionary.ToTensord object at 0x7fdfa37bd7f0>, <filters_and_operators.RandFourierDiskMaskd object at 0x7fdfa37bd760>) 

validation transforms:  (<monai.transforms.io.dictionary.LoadImaged object at 0x7fdfa37bdb20>, <monai.transforms.utility.dictionary.AsChannelFirstd object at 0x7fdfa376c2e0>, <__main__.ConvertToMultiChannelBasedOnBratsClassesd object at 0x7fdfa376c3d0>, <monai.transforms.spatial.dictionary.Spacingd object at 0x7fdfa376c430>, <monai.transforms.spatial.dictionary.Orientationd object at 0x7fdfa376c490>, <monai.transforms.croppad.dictionary.CenterSpatialCropd object at 0x7fdfa376c550>, <monai.transforms.intensity.dictionary.NormalizeIntensityd object at 0x7fdfa376c610>, <monai.transforms.utility.dictionary.ToTensord object at 0x7fdfa376c6a0>, <filters_and_operators.RandFourierDiskMaskd object at 0x7fdfa376c760>) 

Data loaders created.


dict_keys(['image', 'label', 'image_meta_dict', 'label_meta_dict', 'image_transforms', 'label_transforms'])
torch.Size([2, 4, 128, 128, 64])
Model instatitated with number of parameters =  4810074

 Training started... 

----------
epoch 1/3
1/194, train_loss: 0.9712
2/194, train_loss: 0.9694
3/194, train_loss: 0.9395
4/194, train_loss: 0.9521
5/194, train_loss: 0.9456
6/194, train_loss: 0.9328
7/194, train_loss: 0.9446
8/194, train_loss: 0.9474
9/194, train_loss: 0.8984
10/194, train_loss: 0.9318
11/194, train_loss: 0.9416
12/194, train_loss: 0.9225
13/194, train_loss: 0.9301
14/194, train_loss: 0.9797
15/194, train_loss: 0.9504
16/194, train_loss: 0.9404
17/194, train_loss: 0.9423
18/194, train_loss: 0.9310
19/194, train_loss: 0.8907
20/194, train_loss: 0.9569
21/194, train_loss: 0.9614
22/194, train_loss: 0.9574
23/194, train_loss: 0.9584
24/194, train_loss: 0.9629
25/194, train_loss: 0.9536
26/194, train_loss: 0.9779
27/194, train_loss: 0.9289
28/194, train_loss: 0.9146
29/194, train_loss: 0.9353
30/194, train_loss: 0.9687
31/194, train_loss: 0.9017
32/194, train_loss: 0.9630
33/194, train_loss: 0.9375
34/194, train_loss: 0.9894
35/194, train_loss: 0.9462
36/194, train_loss: 0.9062
37/194, train_loss: 0.9051
38/194, train_loss: 0.9597
39/194, train_loss: 0.9511
40/194, train_loss: 0.9522
41/194, train_loss: 0.8955
42/194, train_loss: 0.9502
43/194, train_loss: 0.9839
44/194, train_loss: 0.9693
45/194, train_loss: 0.9134
46/194, train_loss: 0.9310
47/194, train_loss: 0.9121
48/194, train_loss: 0.9454
49/194, train_loss: 0.9022
50/194, train_loss: 0.9133
51/194, train_loss: 0.9166
52/194, train_loss: 0.9465
53/194, train_loss: 0.9315
54/194, train_loss: 0.9123
55/194, train_loss: 0.9307
56/194, train_loss: 0.9550
57/194, train_loss: 0.9471
58/194, train_loss: 0.9301
59/194, train_loss: 0.9783
60/194, train_loss: 0.9110
61/194, train_loss: 0.8805
62/194, train_loss: 0.9050
63/194, train_loss: 0.9710
64/194, train_loss: 0.8820
65/194, train_loss: 0.9392
66/194, train_loss: 0.9311
67/194, train_loss: 0.9263
68/194, train_loss: 0.9243
69/194, train_loss: 0.8948
70/194, train_loss: 0.9218
71/194, train_loss: 0.9832
72/194, train_loss: 0.9117
73/194, train_loss: 0.8937
74/194, train_loss: 0.9571
75/194, train_loss: 0.9202
76/194, train_loss: 0.9513
77/194, train_loss: 0.9373
78/194, train_loss: 0.9282
79/194, train_loss: 0.9212
80/194, train_loss: 0.9418
81/194, train_loss: 0.9828
82/194, train_loss: 0.9660
83/194, train_loss: 0.9591
84/194, train_loss: 0.9608
85/194, train_loss: 0.9151
86/194, train_loss: 0.9468
87/194, train_loss: 0.9143
88/194, train_loss: 0.9736
89/194, train_loss: 0.9440
90/194, train_loss: 0.9461
91/194, train_loss: 0.9441
92/194, train_loss: 0.9437
93/194, train_loss: 0.8988
94/194, train_loss: 0.8941
95/194, train_loss: 0.9434
96/194, train_loss: 0.9420
97/194, train_loss: 0.8589
98/194, train_loss: 0.9322
99/194, train_loss: 0.8965
100/194, train_loss: 0.9207
101/194, train_loss: 0.9511
102/194, train_loss: 0.8691
103/194, train_loss: 0.9010
104/194, train_loss: 0.9372
105/194, train_loss: 0.9423
106/194, train_loss: 0.9627
107/194, train_loss: 0.9523
108/194, train_loss: 0.9192
109/194, train_loss: 0.9640
110/194, train_loss: 0.9040
111/194, train_loss: 0.8864
112/194, train_loss: 0.9423
113/194, train_loss: 0.8764
114/194, train_loss: 0.9534
115/194, train_loss: 0.9559
116/194, train_loss: 0.9219
117/194, train_loss: 0.8785
118/194, train_loss: 0.9273
119/194, train_loss: 0.9038
120/194, train_loss: 0.9392
121/194, train_loss: 0.9101
122/194, train_loss: 0.9349
123/194, train_loss: 0.9229
124/194, train_loss: 0.9457
125/194, train_loss: 0.9288
126/194, train_loss: 0.8616
127/194, train_loss: 0.8468
128/194, train_loss: 0.9703
129/194, train_loss: 0.9087
130/194, train_loss: 0.9413
131/194, train_loss: 0.9023
132/194, train_loss: 0.9639
133/194, train_loss: 0.8839
134/194, train_loss: 0.9648
135/194, train_loss: 0.9522
136/194, train_loss: 0.9294
137/194, train_loss: 0.8962
138/194, train_loss: 0.9628
139/194, train_loss: 0.9235
140/194, train_loss: 0.8907
141/194, train_loss: 0.9219
142/194, train_loss: 0.9205
143/194, train_loss: 0.9708
144/194, train_loss: 0.9574
145/194, train_loss: 0.9092
146/194, train_loss: 0.9451
147/194, train_loss: 0.9001
148/194, train_loss: 0.9826
149/194, train_loss: 0.9013
150/194, train_loss: 0.8907
151/194, train_loss: 0.9313
152/194, train_loss: 0.9330
153/194, train_loss: 0.9581
154/194, train_loss: 0.8676
155/194, train_loss: 0.8684
156/194, train_loss: 0.8803
157/194, train_loss: 0.9355
158/194, train_loss: 0.9256
159/194, train_loss: 0.9334
160/194, train_loss: 0.8776
161/194, train_loss: 0.9578
162/194, train_loss: 0.9565
163/194, train_loss: 0.9168
164/194, train_loss: 0.9669
165/194, train_loss: 0.8998
166/194, train_loss: 0.9450
167/194, train_loss: 0.9138
168/194, train_loss: 0.9399
169/194, train_loss: 0.8963
170/194, train_loss: 0.8808
171/194, train_loss: 0.9438
172/194, train_loss: 0.8917
173/194, train_loss: 0.8746
174/194, train_loss: 0.9337
175/194, train_loss: 0.9475
176/194, train_loss: 0.9340
177/194, train_loss: 0.8412
178/194, train_loss: 0.9833
179/194, train_loss: 0.8842
180/194, train_loss: 0.9063
181/194, train_loss: 0.8581
182/194, train_loss: 0.9083
183/194, train_loss: 0.9522
184/194, train_loss: 0.8837
185/194, train_loss: 0.9452
186/194, train_loss: 0.9159
187/194, train_loss: 0.9011
188/194, train_loss: 0.9207
189/194, train_loss: 0.9434
190/194, train_loss: 0.9327
191/194, train_loss: 0.8894
192/194, train_loss: 0.9746
193/194, train_loss: 0.9486
194/194, train_loss: 0.9036
epoch 1 average loss: 0.9292
----------
epoch 2/3
1/194, train_loss: 0.8976
2/194, train_loss: 0.9203
3/194, train_loss: 0.9136
4/194, train_loss: 0.8911
5/194, train_loss: 0.9134
6/194, train_loss: 0.9511
7/194, train_loss: 0.9602
8/194, train_loss: 0.9096
9/194, train_loss: 0.9366
10/194, train_loss: 0.9886
11/194, train_loss: 0.9140
12/194, train_loss: 0.8497
13/194, train_loss: 0.9066
14/194, train_loss: 0.9201
15/194, train_loss: 0.9043
16/194, train_loss: 0.9215
17/194, train_loss: 0.9008
18/194, train_loss: 0.9751
19/194, train_loss: 0.8831
20/194, train_loss: 0.8648
21/194, train_loss: 0.9490
22/194, train_loss: 0.9580
23/194, train_loss: 0.8743
24/194, train_loss: 0.8976
25/194, train_loss: 0.8698
26/194, train_loss: 0.8913
27/194, train_loss: 0.9142
28/194, train_loss: 0.8711
29/194, train_loss: 0.9179
30/194, train_loss: 0.8996
31/194, train_loss: 0.9415
32/194, train_loss: 0.9559
33/194, train_loss: 0.9143
34/194, train_loss: 0.8762
35/194, train_loss: 0.9246
36/194, train_loss: 0.9392
37/194, train_loss: 0.8859
38/194, train_loss: 0.9520
39/194, train_loss: 0.9443
40/194, train_loss: 0.9336
41/194, train_loss: 0.8864
42/194, train_loss: 0.9362
43/194, train_loss: 0.8915
44/194, train_loss: 0.9038
45/194, train_loss: 0.9165
46/194, train_loss: 0.9050
47/194, train_loss: 0.8738
48/194, train_loss: 0.9592
49/194, train_loss: 0.8469
50/194, train_loss: 0.8909
51/194, train_loss: 0.9281
52/194, train_loss: 0.9400
53/194, train_loss: 0.9466
54/194, train_loss: 0.9283
55/194, train_loss: 0.9163
56/194, train_loss: 0.8880
57/194, train_loss: 0.9546
58/194, train_loss: 0.8769
59/194, train_loss: 0.8937
60/194, train_loss: 0.9487
61/194, train_loss: 0.8020
62/194, train_loss: 0.8067
63/194, train_loss: 0.9024
64/194, train_loss: 0.9510
65/194, train_loss: 0.9224
66/194, train_loss: 0.8997
67/194, train_loss: 0.8896
68/194, train_loss: 0.9290
69/194, train_loss: 0.8713
70/194, train_loss: 0.8624
71/194, train_loss: 0.8881
72/194, train_loss: 0.9415
73/194, train_loss: 0.8689
74/194, train_loss: 0.9286
75/194, train_loss: 0.8929
76/194, train_loss: 0.9302
77/194, train_loss: 0.9052
78/194, train_loss: 0.8942
79/194, train_loss: 0.8690
80/194, train_loss: 0.9506
81/194, train_loss: 0.8825
82/194, train_loss: 0.9295
83/194, train_loss: 0.9587
84/194, train_loss: 0.8448
85/194, train_loss: 0.8464
86/194, train_loss: 0.9087
87/194, train_loss: 0.9319
88/194, train_loss: 0.8253
89/194, train_loss: 0.9334
90/194, train_loss: 0.9217
91/194, train_loss: 0.8908
92/194, train_loss: 0.8532
93/194, train_loss: 0.8370
94/194, train_loss: 0.8948
95/194, train_loss: 0.8749
96/194, train_loss: 0.9353
97/194, train_loss: 0.9117
98/194, train_loss: 0.9209
99/194, train_loss: 0.8996
100/194, train_loss: 0.8875
101/194, train_loss: 0.9760
102/194, train_loss: 0.8970
103/194, train_loss: 0.8900
104/194, train_loss: 0.9101
105/194, train_loss: 0.9335
106/194, train_loss: 0.9076
107/194, train_loss: 0.8525
108/194, train_loss: 0.8946
109/194, train_loss: 0.9231
110/194, train_loss: 0.9095
111/194, train_loss: 0.9198
112/194, train_loss: 0.8673
113/194, train_loss: 0.9154
114/194, train_loss: 0.9347
115/194, train_loss: 0.8973
116/194, train_loss: 0.9319
117/194, train_loss: 0.8479
118/194, train_loss: 0.9184
119/194, train_loss: 0.9068
120/194, train_loss: 0.8235
121/194, train_loss: 0.9049
122/194, train_loss: 0.8910
123/194, train_loss: 0.9500
124/194, train_loss: 0.9860
125/194, train_loss: 0.9725
126/194, train_loss: 0.8861
127/194, train_loss: 0.8725
128/194, train_loss: 0.9311
129/194, train_loss: 0.9105
130/194, train_loss: 0.9035
131/194, train_loss: 0.8815
132/194, train_loss: 0.8633
133/194, train_loss: 0.9238
134/194, train_loss: 0.8974
135/194, train_loss: 0.9147
136/194, train_loss: 0.8534
137/194, train_loss: 0.9335
138/194, train_loss: 0.9073
139/194, train_loss: 0.8800
140/194, train_loss: 0.9124
141/194, train_loss: 0.9419
142/194, train_loss: 0.9513
143/194, train_loss: 0.9588
144/194, train_loss: 0.8889
145/194, train_loss: 0.9210
146/194, train_loss: 0.8750
147/194, train_loss: 0.8934
148/194, train_loss: 0.9537
149/194, train_loss: 0.8645
150/194, train_loss: 0.8823
151/194, train_loss: 0.9292
152/194, train_loss: 0.8722
153/194, train_loss: 0.8256
154/194, train_loss: 0.8786
155/194, train_loss: 0.7779
156/194, train_loss: 0.8904
157/194, train_loss: 0.9635
158/194, train_loss: 0.9618
159/194, train_loss: 0.8843
160/194, train_loss: 0.8502
161/194, train_loss: 0.9371
162/194, train_loss: 0.9002
163/194, train_loss: 0.8889
164/194, train_loss: 0.8799
165/194, train_loss: 0.8530
166/194, train_loss: 0.9810
167/194, train_loss: 0.8887
168/194, train_loss: 0.8808
169/194, train_loss: 0.8559
170/194, train_loss: 0.8821
171/194, train_loss: 0.8830
172/194, train_loss: 0.8830
173/194, train_loss: 0.8255
174/194, train_loss: 0.9703
175/194, train_loss: 0.9357
176/194, train_loss: 0.8760
177/194, train_loss: 0.9225
178/194, train_loss: 0.8791
179/194, train_loss: 0.8769
180/194, train_loss: 0.8803
181/194, train_loss: 0.7785
182/194, train_loss: 0.9205
183/194, train_loss: 0.8566
184/194, train_loss: 0.9540
185/194, train_loss: 0.8308
186/194, train_loss: 0.8919
187/194, train_loss: 0.9452
188/194, train_loss: 0.9154
189/194, train_loss: 0.8073
190/194, train_loss: 0.8629
191/194, train_loss: 0.9599
192/194, train_loss: 0.8752
193/194, train_loss: 0.9099
194/194, train_loss: 0.8849
epoch 2 average loss: 0.9027
Traceback (most recent call last):
  File "/homes/yc7620/Documents/medical-vision-textural-bias/10_scripts/20_Gibbs_filters/stylized_gibbs55_3_epochs.py", line 260, in <module>
    for val_data in val_loader:
  File "/vol/bitbucket/yc7620/miniconda3/envs/torch1p8/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/vol/bitbucket/yc7620/miniconda3/envs/torch1p8/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1182, in _next_data
    idx, data = self._get_data()
  File "/vol/bitbucket/yc7620/miniconda3/envs/torch1p8/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1148, in _get_data
    success, data = self._try_get_data()
  File "/vol/bitbucket/yc7620/miniconda3/envs/torch1p8/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 986, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/vol/bitbucket/yc7620/miniconda3/envs/torch1p8/lib/python3.8/multiprocessing/queues.py", line 116, in get
    return _ForkingPickler.loads(res)
  File "/vol/bitbucket/yc7620/miniconda3/envs/torch1p8/lib/python3.8/site-packages/torch/multiprocessing/reductions.py", line 282, in rebuild_storage_fd
    fd = df.detach()
  File "/vol/bitbucket/yc7620/miniconda3/envs/torch1p8/lib/python3.8/multiprocessing/resource_sharer.py", line 58, in detach
    return reduction.recv_handle(conn)
  File "/vol/bitbucket/yc7620/miniconda3/envs/torch1p8/lib/python3.8/multiprocessing/reduction.py", line 189, in recv_handle
    return recvfds(s, 1)[0]
  File "/vol/bitbucket/yc7620/miniconda3/envs/torch1p8/lib/python3.8/multiprocessing/reduction.py", line 164, in recvfds
    raise RuntimeError('received %d items of ancdata' %
RuntimeError: received 0 items of ancdata
